{"cells":[{"cell_type":"markdown","metadata":{"id":"puWZJzBsuRLQ"},"source":["# Tanpopo1 表面付着物 VGG16+BatchNorm CrossValidation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31829,"status":"ok","timestamp":1671209077694,"user":{"displayName":"Zen Nakamura","userId":"00131218698156176369"},"user_tz":-540},"id":"pYG2cKBZL71t","outputId":"3d85ed0f-8bc5-4416-cd4a-37b125e50f71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}],"source":["# Google Colab マウント\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive\n","import os\n","os.chdir('/content/drive/MyDrive/Tanpopo')\n","\n","from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import torch.utils.data as data\n","\n","import matplotlib.pyplot as plt\n","import glob\n","import time\n","import copy\n","from PIL import Image\n","\n","plt.ion()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsfROiFGycvq"},"outputs":[],"source":["#画像サイズがが704x480 #88x60\n","img_size = 224\n","\n","#class_names = ['1Sputter', '2Fiber', '3Block', '4Bar', '5AGFragment']\n","class_num = 5\n","\n","# 標準化\n","mean = (0.5, 0.5, 0.5)\n","std = (0.5, 0.5, 0.5)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","#torch.set_default_tensor_type('torch.cuda.FloatTensor')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulrYuZyAyZNn"},"outputs":[],"source":["batch_size =  \"16\" #@param[8, 16, 32, 64, 128, 256]\n","batch_size = int(batch_size)\n","\n","epochs = \"25\" #@param[5, 8, 10, 15, 20, 22, 25, 27, 29, 30, 31, 32, 33, 35, 45, 60, 120]\n","epochs = int(epochs)"]},{"cell_type":"markdown","metadata":{"id":"mYj7Qs5o1cOA"},"source":["### 関数、クラスの定義"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDTiz8vk6MrK"},"outputs":[],"source":["import random\n","from sklearn.model_selection import train_test_split\n","def make_filepath_list(folderpath, phase='train'):\n","    \"\"\"\n","    ファイルのパスを格納したリストを返す\n","    \"\"\"\n","    # .DS_Storeが最初に読み込まれる\n","    file_list = []\n","    files_list = []\n","    class_names = []\n","\n","    for index, top_dir in enumerate(sorted(os.listdir(folderpath))):\n","        file_dir = os.path.join(folderpath, top_dir)\n","        file_list = glob.glob(file_dir + '/*bmp')\n","\n","        if top_dir != '.DS_Store':\n","            class_names.append(top_dir)\n","            files_list += [os.path.join(folderpath, top_dir, file).replace('\\\\', '/') for file in file_list]\n","                                                            \n","    return files_list, class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXiTLeVIxYDC"},"outputs":[],"source":["class ImageTransform(object):\n","    \"\"\"\n","    画像の前処理\n","    \"\"\"\n","    def __init__(self, resize, mean, std):\n","        self.data_transform = {\n","            'train': transforms.Compose([\n","                # データオグメンテーション, 前処理\n","                transforms.Resize(256), # リサイズ\n","                transforms.CenterCrop(resize), # 切り取り\n","                transforms.RandomRotation(45), # ランタムに回転\n","                transforms.ColorJitter(), # ランダムに明るさ、コントラスト、彩度、色相を変化\n","                transforms.RandomHorizontalFlip(), # ランダムに左右(水平)反転\n","                transforms.RandomVerticalFlip(), # ランダムに上下(垂直)反転\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std), # zcaと交換？\n","                # ZCA whitening追加する\n","            ]),\n","            'valid': transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(resize),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std),\n","            ]),\n","            'test': transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(resize),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean, std),\n","            ])\n","        }\n","\n","    def __call__(self, img, phase='train'):\n","        return self.data_transform[phase](img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"astLB_KNKi3v"},"outputs":[],"source":["from torchvision.io import read_image\n","\n","class SurfaceObjectDataset(data.Dataset):\n","    \"\"\"\n","    表面付着物のDatasetクラス\n","    PyTorchのDatasetクラスを継承\n","    \"\"\"\n","    def __init__(self, file_list, classes, transform=None, phase='train'):\n","        #super().__init__()\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.classes = classes\n","        self.phase = phase\n","\n","        self.img = None\n","        self.label = None\n","\n","    def __len__(self):\n","        \"\"\"\n","        画像の枚数を返す\n","        \"\"\"\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        前処理した画像データのTensor形式のデータとラベルを取得\n","        \"\"\"\n","        # 指定したindexの画像を読み込む\n","        img_path = self.file_list[index]\n","        img = Image.open(img_path)\n","\n","        # 画像ラベルをファイル名から抜き出す\n","        label = self.file_list[index].split('/')[6][:11]\n","\n","        # ラベル名を数値に変換\n","        label = self.classes.index(label)\n","\n","        # 画像の前処理を実施\n","        if self.transform is not None:\n","            img_transformed = self.transform(img, self.phase)\n","        \n","        self.img = img_transformed\n","        self.label = label\n","\n","        return img_transformed, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEgn6SzApOak"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","\n","        # 各エポックには訓練フェーズと検証フェーズがあります\n","        for phase in ['train', 'valid']:\n","            if phase == 'train':\n","                model.train()  # モデルを訓練モードに設定します\n","            else:\n","                model.eval()   # モードを評価するモデルを設定します\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # データをイレテートします\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # パラメータの勾配をゼロにします\n","                optimizer.zero_grad()\n","\n","                # 順伝播\n","                # 訓練の時だけ、履歴を保持します\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # 訓練の時だけ逆伝播＋オプティマイズを行います\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # 損失を計算します\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print(' {} Loss: {:.4f} Acc: {:.4f} '.format(\n","                phase, epoch_loss, epoch_acc), end='\\t')\n","\n","            # モデルをディープ・コピーします\n","            if phase == 'valid' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # ベストモデルの重みをロードします\n","    model.load_state_dict(best_model_wts)\n","    return model, best_acc"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import numpy as np\n","\n","#正解\n","def class_accuracy(label, conf_mat):\n","    return (conf_mat[label][label] + (np.sum(conf_mat) - (np.sum(conf_mat[:, label])+np.sum(conf_mat[label])-conf_mat[label][label]))) / np.sum(conf_mat)\n","    \n","#精度(適合率)\n","def class_precision(label, conf_mat):\n","    return conf_mat[label][label] / np.sum(conf_mat[label])\n","\n","#再現率\n","def class_recall(label, conf_mat):\n","    return conf_mat[label][label] / np.sum(conf_mat[:, label])\n","\n","# テスト結果を返す\n","def test_model(model, test_dataloaders):\n","    labels_sum = None\n","    predicted_sum = None\n","\n","    with torch.no_grad():\n","        for data in test_dataloaders:\n","            images, labels = data\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","\n","            #outputs = nn.Softmax(dim=1)(outputs)\n","\n","            _, predicted = torch.max(outputs, 1)\n","\n","            if labels_sum is None:\n","                labels_sum = labels\n","                predicted_sum = predicted\n","            else:\n","                labels_sum = torch.cat([labels_sum, labels], dim=0)\n","                predicted_sum = torch.cat([predicted_sum, predicted], dim=0)\n","\n","    #混同行列\n","    labels_sum = labels_sum.cpu()\n","    predicted_sum = predicted_sum.cpu()\n","    conf_mat = None\n","    Accuracy = []\n","    Precision = []\n","    Recall = []\n","\n","    conf_mat = confusion_matrix(labels_sum, predicted_sum)\n","\n","    for i in range(class_num):\n","        Accuracy = np.append(Accuracy, class_accuracy(i, conf_mat)*100)\n","        Precision = np.append(Precision, class_precision(i, conf_mat)*100)\n","        Recall = np.append(Recall, class_recall(i, conf_mat)*100)\n","\n","    return conf_mat, Accuracy, Precision, Recall"],"metadata":{"id":"UegpCVJjzcht"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### モデルの作成"],"metadata":{"id":"H-tZ7UhJzd-h"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8263,"status":"ok","timestamp":1671209091045,"user":{"displayName":"Zen Nakamura","userId":"00131218698156176369"},"user_tz":-540},"id":"r-0-coGwl-Og","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["bbe61d231fe34f399b0cdfd1fd691e55","97301d20628b45c880fef6603a76f11e","442146d539ef4c64b5491b965b120adf","5b2602f1b2214b339c21b1f31cfe6c13","a6bc7866312845f2afb4daea55738816","f73934c7970c4a7699373713f3c4f90c","1ca4d501ef2347eaae4702ae407b037d","993bfa8efd7a4d629ada360abd7e278b","e00007bc358441e2a319c45d314c0bdc","147bd8eaf26e4413aa4e4bf58072444b","dcbdb86a7b74462c9138c7b12bca41cc"]},"outputId":"9ed75454-347d-4e3e-a727-28871e289b1b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/528M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe61d231fe34f399b0cdfd1fd691e55"}},"metadata":{}}],"source":["# モデルをロード\n","# VGG16学習済みの重みを使用\n","model_vgg16 = models.vgg16(pretrained=True)\n","model_vgg16BatchNorm = None # VGG16+Batch Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfamGGLH6cbV"},"outputs":[],"source":["#print(model_vgg16)"]},{"cell_type":"code","source":["def Add_BatchNorm(pretrained_vgg16, class_num):\n","    if model_vgg16BatchNorm is None:\n","        # VGG16 に BatchNorm　を挿入 (ReLU層とMax Pool2d層の間)\n","        pretrained_vgg16.features.insert(4, nn.BatchNorm2d(64))\n","        pretrained_vgg16.features.insert(10, nn.BatchNorm2d(128))\n","        pretrained_vgg16.features.insert(18, nn.BatchNorm2d(256))\n","        pretrained_vgg16.features.insert(26, nn.BatchNorm2d(512))\n","        pretrained_vgg16.features.insert(34, nn.BatchNorm2d(512))\n","\n","        # 最後の層\n","        pretrained_vgg16.classifier[6] = nn.Linear(4096, class_num)\n","\n","    return pretrained_vgg16\n","\n","\n","model_vgg16BatchNorm = Add_BatchNorm(model_vgg16, class_num)\n","model_vgg16BatchNorm.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjNqUDuStGuk","executionInfo":{"status":"ok","timestamp":1671209098425,"user_tz":-540,"elapsed":7385,"user":{"displayName":"Zen Nakamura","userId":"00131218698156176369"}},"outputId":"f576f9be-1816-4b7c-8c4f-b6c5d4148532"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace=True)\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): ReLU(inplace=True)\n","    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (23): ReLU(inplace=True)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): ReLU(inplace=True)\n","    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (33): ReLU(inplace=True)\n","    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (35): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=5, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# まず全パラメータを勾配計算Falseにする\n","for param in model_vgg16BatchNorm.parameters():\n","    param.requires_grad = False\n","\n","params_to_update = []\n","\n","# Batch Normalization 重み変更\n","batch_idx = [4, 10, 18, 26, 34]\n","for idx in batch_idx:\n","    for param in model_vgg16BatchNorm.features[idx].parameters():\n","        param.requires_grad = True\n","        params_to_update.append(param)\n","    \n","# 追加したクラス分類用の全結合層を勾配計算ありに変更\n","for param in model_vgg16BatchNorm.classifier.parameters():\n","    param.requires_grad = True\n","    params_to_update.append(param)\n","\n","optimizer = optim.AdamW(params_to_update, lr=0.001, weight_decay=0.001) # BatchNormを入れることでlrを大きくできる？\n","# lr(Learning Rate)を大きくすると局所minになりずらい\n","\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"YVqWtsxj6gk4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 学習"],"metadata":{"id":"kr033mgF7VH0"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":788503,"status":"ok","timestamp":1671209978920,"user":{"displayName":"Zen Nakamura","userId":"00131218698156176369"},"user_tz":-540},"id":"6PJTRWVfWl98","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0e020355-1999-480e-c7f6-d9d2e057586f"},"outputs":[{"output_type":"stream","name":"stdout","text":["-----1-----\n","Epoch 0/24\n"," train Loss: 0.2062 Acc: 0.9337 \t valid Loss: 0.1313 Acc: 0.9592 \t\n","Epoch 1/24\n"," train Loss: 0.2125 Acc: 0.9337 \t valid Loss: 0.1117 Acc: 0.9592 \t\n","Epoch 2/24\n"," train Loss: 0.3537 Acc: 0.9184 \t valid Loss: 0.1022 Acc: 0.9592 \t\n","Epoch 3/24\n"," train Loss: 0.4683 Acc: 0.8929 \t valid Loss: 0.1483 Acc: 0.9592 \t\n","Epoch 4/24\n"," train Loss: 0.2502 Acc: 0.9337 \t valid Loss: 0.0606 Acc: 1.0000 \t\n","Epoch 5/24\n"," train Loss: 0.2252 Acc: 0.9337 \t valid Loss: 0.1748 Acc: 0.9592 \t\n","Epoch 6/24\n"," train Loss: 0.2981 Acc: 0.9082 \t valid Loss: 0.0674 Acc: 1.0000 \t\n","Epoch 7/24\n"," train Loss: 0.1578 Acc: 0.9337 \t valid Loss: 0.1099 Acc: 0.9388 \t\n","Epoch 8/24\n"," train Loss: 0.3432 Acc: 0.9082 \t valid Loss: 0.1000 Acc: 0.9592 \t\n","Epoch 9/24\n"," train Loss: 0.1770 Acc: 0.9337 \t valid Loss: 0.0805 Acc: 0.9796 \t\n","Epoch 10/24\n"," train Loss: 0.2670 Acc: 0.9439 \t valid Loss: 0.0502 Acc: 1.0000 \t\n","Epoch 11/24\n"," train Loss: 0.1770 Acc: 0.9490 \t valid Loss: 0.0867 Acc: 0.9592 \t\n","Epoch 12/24\n"," train Loss: 0.2885 Acc: 0.9235 \t valid Loss: 0.1509 Acc: 0.9796 \t\n","Epoch 13/24\n"," train Loss: 0.1824 Acc: 0.9388 \t valid Loss: 0.0871 Acc: 0.9796 \t\n","Epoch 14/24\n"," train Loss: 0.3426 Acc: 0.9388 \t valid Loss: 0.0664 Acc: 1.0000 \t\n","Epoch 15/24\n"," train Loss: 0.2052 Acc: 0.9286 \t valid Loss: 0.1032 Acc: 0.9592 \t\n","Epoch 16/24\n"," train Loss: 0.1111 Acc: 0.9490 \t valid Loss: 0.1114 Acc: 0.9592 \t\n","Epoch 17/24\n"," train Loss: 0.3194 Acc: 0.9235 \t valid Loss: 0.1183 Acc: 0.9592 \t\n","Epoch 18/24\n"," train Loss: 0.1518 Acc: 0.9490 \t valid Loss: 0.0533 Acc: 1.0000 \t\n","Epoch 19/24\n"," train Loss: 0.2065 Acc: 0.9592 \t valid Loss: 0.0844 Acc: 0.9388 \t\n","Epoch 20/24\n"," train Loss: 0.1593 Acc: 0.9439 \t valid Loss: 0.0778 Acc: 0.9388 \t\n","Epoch 21/24\n"," train Loss: 0.2308 Acc: 0.8980 \t valid Loss: 0.0777 Acc: 0.9796 \t\n","Epoch 22/24\n"," train Loss: 0.2006 Acc: 0.9337 \t valid Loss: 0.0481 Acc: 1.0000 \t\n","Epoch 23/24\n"," train Loss: 0.1842 Acc: 0.9388 \t valid Loss: 0.1890 Acc: 0.9592 \t\n","Epoch 24/24\n"," train Loss: 0.2943 Acc: 0.9082 \t valid Loss: 0.2970 Acc: 0.9388 \t\n","Training complete in 4m 16s\n","Best val Acc: 1.000000\n","-----2-----\n","Epoch 0/24\n"," train Loss: 0.4351 Acc: 0.9133 \t valid Loss: 0.0524 Acc: 1.0000 \t\n","Epoch 1/24\n"," train Loss: 0.2248 Acc: 0.9082 \t valid Loss: 0.0720 Acc: 0.9796 \t\n","Epoch 2/24\n"," train Loss: 0.1551 Acc: 0.9541 \t valid Loss: 0.0946 Acc: 0.9592 \t\n","Epoch 3/24\n"," train Loss: 0.1317 Acc: 0.9490 \t valid Loss: 0.0737 Acc: 0.9592 \t\n","Epoch 4/24\n"," train Loss: 0.1522 Acc: 0.9694 \t valid Loss: 0.0759 Acc: 0.9796 \t\n","Epoch 5/24\n"," train Loss: 0.1074 Acc: 0.9643 \t valid Loss: 0.0856 Acc: 0.9796 \t\n","Epoch 6/24\n"," train Loss: 0.1790 Acc: 0.9184 \t valid Loss: 0.1073 Acc: 0.9796 \t\n","Epoch 7/24\n"," train Loss: 0.1994 Acc: 0.9286 \t valid Loss: 0.1062 Acc: 0.9592 \t\n","Epoch 8/24\n"," train Loss: 0.2123 Acc: 0.9235 \t valid Loss: 0.1918 Acc: 0.9184 \t\n","Epoch 9/24\n"," train Loss: 0.2816 Acc: 0.9133 \t valid Loss: 0.1232 Acc: 0.9796 \t\n","Epoch 10/24\n"," train Loss: 0.1959 Acc: 0.9337 \t valid Loss: 0.0925 Acc: 0.9592 \t\n","Epoch 11/24\n"," train Loss: 0.1668 Acc: 0.9439 \t valid Loss: 0.1492 Acc: 0.9592 \t\n","Epoch 12/24\n"," train Loss: 0.2117 Acc: 0.9235 \t valid Loss: 0.1136 Acc: 0.9592 \t\n","Epoch 13/24\n"," train Loss: 0.2528 Acc: 0.9235 \t valid Loss: 0.1602 Acc: 0.9592 \t\n","Epoch 14/24\n"," train Loss: 0.1550 Acc: 0.9337 \t valid Loss: 0.2201 Acc: 0.9184 \t\n","Epoch 15/24\n"," train Loss: 0.1732 Acc: 0.9439 \t valid Loss: 0.2123 Acc: 0.9592 \t\n","Epoch 16/24\n"," train Loss: 0.1658 Acc: 0.9337 \t valid Loss: 0.1499 Acc: 0.9592 \t\n","Epoch 17/24\n"," train Loss: 0.1835 Acc: 0.9388 \t valid Loss: 0.0802 Acc: 0.9796 \t\n","Epoch 18/24\n"," train Loss: 0.2220 Acc: 0.9082 \t valid Loss: 0.1812 Acc: 0.9388 \t\n","Epoch 19/24\n"," train Loss: 0.1735 Acc: 0.9388 \t valid Loss: 0.1873 Acc: 0.9592 \t\n","Epoch 20/24\n"," train Loss: 0.1716 Acc: 0.9643 \t valid Loss: 0.1187 Acc: 0.9796 \t\n","Epoch 21/24\n"," train Loss: 0.1641 Acc: 0.9286 \t valid Loss: 0.2807 Acc: 0.9184 \t\n","Epoch 22/24\n"," train Loss: 0.1789 Acc: 0.9439 \t valid Loss: 0.6745 Acc: 0.8980 \t\n","Epoch 23/24\n"," train Loss: 0.3541 Acc: 0.9082 \t valid Loss: 0.1001 Acc: 0.9796 \t\n","Epoch 24/24\n"," train Loss: 0.1310 Acc: 0.9592 \t valid Loss: 0.1301 Acc: 0.9796 \t\n","Training complete in 1m 54s\n","Best val Acc: 1.000000\n","-----3-----\n","Epoch 0/24\n"," train Loss: 0.1751 Acc: 0.9388 \t valid Loss: 0.2442 Acc: 0.9388 \t\n","Epoch 1/24\n"," train Loss: 0.1316 Acc: 0.9490 \t valid Loss: 0.1108 Acc: 0.9796 \t\n","Epoch 2/24\n"," train Loss: 0.2537 Acc: 0.9286 \t valid Loss: 0.0637 Acc: 1.0000 \t\n","Epoch 3/24\n"," train Loss: 0.3481 Acc: 0.9235 \t valid Loss: 0.1676 Acc: 0.9592 \t\n","Epoch 4/24\n"," train Loss: 0.1416 Acc: 0.9439 \t valid Loss: 0.2297 Acc: 0.9388 \t\n","Epoch 5/24\n"," train Loss: 0.3261 Acc: 0.9235 \t valid Loss: 0.1881 Acc: 0.9592 \t\n","Epoch 6/24\n"," train Loss: 0.1714 Acc: 0.9439 \t valid Loss: 0.1684 Acc: 0.9592 \t\n","Epoch 7/24\n"," train Loss: 0.1944 Acc: 0.9388 \t valid Loss: 0.1633 Acc: 0.9592 \t\n","Epoch 8/24\n"," train Loss: 0.1524 Acc: 0.9388 \t valid Loss: 0.1998 Acc: 0.8980 \t\n","Epoch 9/24\n"," train Loss: 0.2753 Acc: 0.9184 \t valid Loss: 0.1284 Acc: 0.9592 \t\n","Epoch 10/24\n"," train Loss: 0.2698 Acc: 0.9439 \t valid Loss: 0.1090 Acc: 1.0000 \t\n","Epoch 11/24\n"," train Loss: 0.1745 Acc: 0.9439 \t valid Loss: 0.1585 Acc: 0.9796 \t\n","Epoch 12/24\n"," train Loss: 0.2096 Acc: 0.9082 \t valid Loss: 0.1977 Acc: 0.9184 \t\n","Epoch 13/24\n"," train Loss: 0.1989 Acc: 0.9337 \t valid Loss: 0.1997 Acc: 0.9592 \t\n","Epoch 14/24\n"," train Loss: 0.2276 Acc: 0.9286 \t valid Loss: 0.1622 Acc: 0.9184 \t\n","Epoch 15/24\n"," train Loss: 0.1811 Acc: 0.9490 \t valid Loss: 0.1328 Acc: 0.9592 \t\n","Epoch 16/24\n"," train Loss: 0.1572 Acc: 0.9643 \t valid Loss: 0.1182 Acc: 0.9592 \t\n","Epoch 17/24\n"," train Loss: 0.1827 Acc: 0.9235 \t valid Loss: 0.1489 Acc: 0.9388 \t\n","Epoch 18/24\n"," train Loss: 0.1337 Acc: 0.9643 \t valid Loss: 0.1657 Acc: 0.9388 \t\n","Epoch 19/24\n"," train Loss: 0.1895 Acc: 0.9388 \t valid Loss: 0.0773 Acc: 1.0000 \t\n","Epoch 20/24\n"," train Loss: 0.1170 Acc: 0.9592 \t valid Loss: 0.1484 Acc: 0.9388 \t\n","Epoch 21/24\n"," train Loss: 0.1805 Acc: 0.9388 \t valid Loss: 0.1333 Acc: 0.9388 \t\n","Epoch 22/24\n"," train Loss: 0.0880 Acc: 0.9592 \t valid Loss: 0.2786 Acc: 0.8776 \t\n","Epoch 23/24\n"," train Loss: 0.3453 Acc: 0.9235 \t valid Loss: 0.1548 Acc: 0.9388 \t\n","Epoch 24/24\n"," train Loss: 0.1564 Acc: 0.9541 \t valid Loss: 0.1600 Acc: 0.9592 \t\n","Training complete in 1m 54s\n","Best val Acc: 1.000000\n","-----4-----\n","Epoch 0/24\n"," train Loss: 0.1517 Acc: 0.9337 \t valid Loss: 0.0305 Acc: 0.9796 \t\n","Epoch 1/24\n"," train Loss: 0.1926 Acc: 0.9439 \t valid Loss: 0.0254 Acc: 1.0000 \t\n","Epoch 2/24\n"," train Loss: 0.2035 Acc: 0.9286 \t valid Loss: 0.0094 Acc: 1.0000 \t\n","Epoch 3/24\n"," train Loss: 0.1406 Acc: 0.9439 \t valid Loss: 0.0186 Acc: 1.0000 \t\n","Epoch 4/24\n"," train Loss: 0.3262 Acc: 0.9133 \t valid Loss: 0.0199 Acc: 1.0000 \t\n","Epoch 5/24\n"," train Loss: 0.1871 Acc: 0.9337 \t valid Loss: 0.0308 Acc: 1.0000 \t\n","Epoch 6/24\n"," train Loss: 0.1823 Acc: 0.9337 \t valid Loss: 0.0353 Acc: 0.9796 \t\n","Epoch 7/24\n"," train Loss: 0.2222 Acc: 0.9388 \t valid Loss: 0.1637 Acc: 0.9592 \t\n","Epoch 8/24\n"," train Loss: 0.1980 Acc: 0.9184 \t valid Loss: 0.0335 Acc: 1.0000 \t\n","Epoch 9/24\n"," train Loss: 0.2376 Acc: 0.9235 \t valid Loss: 0.0240 Acc: 1.0000 \t\n","Epoch 10/24\n"," train Loss: 0.1904 Acc: 0.9337 \t valid Loss: 0.0409 Acc: 0.9796 \t\n","Epoch 11/24\n"," train Loss: 0.1544 Acc: 0.9388 \t valid Loss: 0.0505 Acc: 0.9796 \t\n","Epoch 12/24\n"," train Loss: 0.2723 Acc: 0.9082 \t valid Loss: 0.1033 Acc: 0.9592 \t\n","Epoch 13/24\n"," train Loss: 0.1670 Acc: 0.9490 \t valid Loss: 0.0114 Acc: 1.0000 \t\n","Epoch 14/24\n"," train Loss: 0.1667 Acc: 0.9439 \t valid Loss: 0.0490 Acc: 0.9796 \t\n","Epoch 15/24\n"," train Loss: 0.1998 Acc: 0.9388 \t valid Loss: 0.1070 Acc: 0.9592 \t\n","Epoch 16/24\n"," train Loss: 0.1481 Acc: 0.9439 \t valid Loss: 0.0525 Acc: 0.9796 \t\n","Epoch 17/24\n"," train Loss: 0.1772 Acc: 0.9439 \t valid Loss: 0.0744 Acc: 0.9796 \t\n","Epoch 18/24\n"," train Loss: 0.3045 Acc: 0.9337 \t valid Loss: 0.0867 Acc: 0.9796 \t\n","Epoch 19/24\n"," train Loss: 0.2631 Acc: 0.9133 \t valid Loss: 0.1085 Acc: 0.9592 \t\n","Epoch 20/24\n"," train Loss: 0.1917 Acc: 0.9337 \t valid Loss: 0.0163 Acc: 1.0000 \t\n","Epoch 21/24\n"," train Loss: 0.1822 Acc: 0.9388 \t valid Loss: 0.0844 Acc: 0.9388 \t\n","Epoch 22/24\n"," train Loss: 0.1764 Acc: 0.9337 \t valid Loss: 0.0430 Acc: 1.0000 \t\n","Epoch 23/24\n"," train Loss: 0.2541 Acc: 0.9184 \t valid Loss: 0.0453 Acc: 0.9796 \t\n","Epoch 24/24\n"," train Loss: 0.3944 Acc: 0.8980 \t valid Loss: 0.1128 Acc: 0.9796 \t\n","Training complete in 1m 55s\n","Best val Acc: 1.000000\n","-----5-----\n","Epoch 0/24\n"," train Loss: 0.2367 Acc: 0.9388 \t valid Loss: 0.1263 Acc: 0.9388 \t\n","Epoch 1/24\n"," train Loss: 0.2626 Acc: 0.9235 \t valid Loss: 0.0747 Acc: 0.9592 \t\n","Epoch 2/24\n"," train Loss: 0.1252 Acc: 0.9439 \t valid Loss: 0.1208 Acc: 0.9592 \t\n","Epoch 3/24\n"," train Loss: 0.1842 Acc: 0.9337 \t valid Loss: 0.1203 Acc: 0.9592 \t\n","Epoch 4/24\n"," train Loss: 0.1672 Acc: 0.9439 \t valid Loss: 0.0791 Acc: 0.9592 \t\n","Epoch 5/24\n"," train Loss: 0.2633 Acc: 0.9184 \t valid Loss: 0.1049 Acc: 0.9592 \t\n","Epoch 6/24\n"," train Loss: 0.1026 Acc: 0.9694 \t valid Loss: 0.1764 Acc: 0.9184 \t\n","Epoch 7/24\n"," train Loss: 0.2357 Acc: 0.9388 \t valid Loss: 0.1296 Acc: 0.9592 \t\n","Epoch 8/24\n"," train Loss: 0.2240 Acc: 0.9337 \t valid Loss: 0.0992 Acc: 0.9388 \t\n","Epoch 9/24\n"," train Loss: 0.1448 Acc: 0.9541 \t valid Loss: 0.2382 Acc: 0.9184 \t\n","Epoch 10/24\n"," train Loss: 0.1213 Acc: 0.9592 \t valid Loss: 0.1483 Acc: 0.9592 \t\n","Epoch 11/24\n"," train Loss: 0.2142 Acc: 0.9082 \t valid Loss: 0.0680 Acc: 0.9796 \t\n","Epoch 12/24\n"," train Loss: 0.3436 Acc: 0.9388 \t valid Loss: 0.0434 Acc: 0.9796 \t\n","Epoch 13/24\n"," train Loss: 0.1488 Acc: 0.9490 \t valid Loss: 0.1071 Acc: 0.9592 \t\n","Epoch 14/24\n"," train Loss: 0.2805 Acc: 0.9286 \t valid Loss: 0.2419 Acc: 0.9388 \t\n","Epoch 15/24\n"," train Loss: 0.1220 Acc: 0.9439 \t valid Loss: 0.2217 Acc: 0.8980 \t\n","Epoch 16/24\n"," train Loss: 0.2483 Acc: 0.9235 \t valid Loss: 0.0631 Acc: 0.9592 \t\n","Epoch 17/24\n"," train Loss: 0.2055 Acc: 0.9439 \t valid Loss: 0.1186 Acc: 0.9592 \t\n","Epoch 18/24\n"," train Loss: 0.2397 Acc: 0.9235 \t valid Loss: 0.2316 Acc: 0.9184 \t\n","Epoch 19/24\n"," train Loss: 0.2036 Acc: 0.9388 \t valid Loss: 0.1988 Acc: 0.9184 \t\n","Epoch 20/24\n"," train Loss: 0.1120 Acc: 0.9745 \t valid Loss: 0.1471 Acc: 0.9388 \t\n","Epoch 21/24\n"," train Loss: 0.1110 Acc: 0.9643 \t valid Loss: 0.1441 Acc: 0.9388 \t\n","Epoch 22/24\n"," train Loss: 0.2103 Acc: 0.9541 \t valid Loss: 0.0334 Acc: 1.0000 \t\n","Epoch 23/24\n"," train Loss: 0.2424 Acc: 0.9388 \t valid Loss: 0.1018 Acc: 0.9592 \t\n","Epoch 24/24\n"," train Loss: 0.2376 Acc: 0.9388 \t valid Loss: 0.1951 Acc: 0.9388 \t\n","Training complete in 1m 55s\n","Best val Acc: 1.000000\n"]}],"source":["from torch.utils.data.dataset import Subset\n","from sklearn.model_selection import KFold\n","from  torch.utils.data import Dataset\n","\n","# 訓練、検証データへのファイルパスを格納したリストを取得\n","train_file_list, class_names = make_filepath_list('/content/drive/MyDrive/Tanpopo/TrainingData11', 'train')\n","#print('train_file_list: ', train_file_list)\n","#print('class_names: ', class_names)\n","class_num = len(class_names) # 5\n","\n","dataset = SurfaceObjectDataset(\n","        file_list = train_file_list, classes = class_names,\n","        transform = ImageTransform(img_size, mean, std),\n","        phase = 'train')\n","\n","# テストデータ\n","test_file_list, class_names_test = make_filepath_list('/content/drive/MyDrive/Tanpopo/TestData11', 'test')\n","#print('test_file_list : ', test_file_list)\n","#print('class_names_test : ', class_names_test)\n","\n","# Datasetの作成\n","test_dataset = SurfaceObjectDataset(\n","    file_list = test_file_list, classes = class_names_test,\n","    transform = ImageTransform(img_size, mean, std),\n","    phase = 'test')\n","# Dataloaderの作成\n","test_dataloader = data.DataLoader(\n","    test_dataset, batch_size = int(batch_size/2), shuffle=False)\n","dataloaders_dict = {'test': test_dataloader}\n","\n","\n","# K-Fold 交差検証 \n","kf = KFold(n_splits=5, shuffle=True, random_state=1) # 5回検証\n","\n","scores = []\n","test_accuracy = []\n","test_precision = []\n","test_recall = []\n","conf_mat = []\n","\n","PATH = '/content/drive/MyDrive/Tanpopo/model_vgg16BatchNorm_weights.pth'\n","model_vgg16BatchNorm.load_state_dict(torch.load(PATH)) # 学習前: 前回の重みを使う\n","\n","for _fold, (train_index, valid_index) in enumerate(kf.split(train_file_list)):\n","    # Datasetの作成\n","    train_dataset = Subset(dataset, train_index)\n","    valid_dataset = Subset(dataset, valid_index)\n","    # Dataloaderの作成\n","    train_dataloader = data.DataLoader(\n","        train_dataset, batch_size = batch_size, shuffle=True)\n","    valid_dataloader = data.DataLoader(\n","        valid_dataset, batch_size = int(batch_size/2), shuffle=False)\n","    \n","    dataloaders_dict['train'] = train_dataloader\n","    dataloaders_dict['valid'] = valid_dataloader\n","\n","    print('-'*5, end='')\n","    print(_fold+1, end='')\n","    print('-'*5)\n","    model_vgg16BatchNorm = model_vgg16BatchNorm.to(device)\n","    model_vgg16BatchNorm, score = train_model(model_vgg16BatchNorm, dataloaders_dict, criterion, optimizer, num_epochs=epochs)\n","    scores.append(score.to('cpu'))\n","\n","    conf, test_acc, test_prec, test_rec = test_model(model_vgg16BatchNorm, dataloaders_dict['test'])\n","    \n","    test_accuracy.append(test_acc)\n","    test_precision.append(test_prec)\n","    test_recall.append(test_rec)\n","    conf_mat.append(conf)"]},{"cell_type":"code","source":["# Validation \n","print('VGG16 + BatchNormalization Result')\n","print(f'Validation Accuracy: 平均 {np.mean(scores)*100:.1f} 標準偏差 {np.std(cores)*100:.4f}')\n","\n","# Test\n","print('Test results:')\n","print(class_names)\n","\n","tmp_list = [] # Accuracy\n","print('Accuracy:', end='\\t')\n","for i in range(class_num):\n","    tmp_list = [r[i] for r in test_accuracy]\n","    means = np.mean(tmp_list)\n","    stds = np.std(tmp_list)\n","    print(f'{np.mean(tmp_list):.1f}±{np.std(tmp_list):.2f}', end='\\t')\n","\n","tmp_list = [] # Precision\n","print('\\nPrecision:', end='\\t')\n","for i in range(class_num):\n","    tmp_list = [r[i] for r in test_precision]\n","    means = np.mean(tmp_list)\n","    stds = np.std(tmp_list)\n","    print(f'{np.mean(tmp_list):.1f}±{np.std(tmp_list):.2f}', end='\\t')\n","\n","tmp_list = [] # Recall\n","print('\\nRecall:', end='\\t')\n","for i in range(class_num):\n","    tmp_list = [r[i] for r in test_recall]\n","    means = np.mean(tmp_list)\n","    stds = np.std(tmp_list)\n","    print(f'{np.mean(tmp_list):.1f}±{np.std(tmp_list):.2f}', end='\\t')\n","\n","print('\\nConf Matrix:') # 混同行列\n","for i in range(class_num):\n","    print([r[i] for r in conf_mat])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDecKgEU0TNL","executionInfo":{"status":"ok","timestamp":1671210124465,"user_tz":-540,"elapsed":8,"user":{"displayName":"Zen Nakamura","userId":"00131218698156176369"}},"outputId":"f9e05715-391e-40f6-8441-729d3bcd3666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGG16 + BatchNormalizatoin Result\n","Validation Accuracy: 平均 100.0 標準偏差 0.0000\n","Test results:\n","['1Sputter', '2Fiber', '3Block', '4Bar', '5AGFragment']\n","Accuracy:\t100.0±0.00\t98.1±0.00\t99.8±0.38\t99.0±0.00\t98.9±0.38\t\n","Precision:\t100.0±0.00\t95.2±0.00\t100.0±0.00\t100.0±0.00\t94.3±1.90\t\n","Recall:\t100.0±0.00\t95.2±0.00\t99.1±1.82\t95.5±0.00\t100.0±0.00\t\n","Conf Matrix:\n","[array([21,  0,  0,  0,  0]), array([21,  0,  0,  0,  0]), array([21,  0,  0,  0,  0]), array([21,  0,  0,  0,  0]), array([21,  0,  0,  0,  0])]\n","[array([ 0, 20,  0,  1,  0]), array([ 0, 20,  0,  1,  0]), array([ 0, 20,  0,  1,  0]), array([ 0, 20,  0,  1,  0]), array([ 0, 20,  0,  1,  0])]\n","[array([ 0,  0, 21,  0,  0]), array([ 0,  0, 21,  0,  0]), array([ 0,  0, 21,  0,  0]), array([ 0,  0, 21,  0,  0]), array([ 0,  0, 21,  0,  0])]\n","[array([ 0,  0,  0, 21,  0]), array([ 0,  0,  0, 21,  0]), array([ 0,  0,  0, 21,  0]), array([ 0,  0,  0, 21,  0]), array([ 0,  0,  0, 21,  0])]\n","[array([ 0,  1,  0,  0, 20]), array([ 0,  1,  1,  0, 19]), array([ 0,  1,  0,  0, 20]), array([ 0,  1,  0,  0, 20]), array([ 0,  1,  0,  0, 20])]\n"]}]},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/Tanpopo/model_vgg16_weights.pth'\n","#torch.save(model_vgg16.state_dict(), PATH) # 重みを保存"],"metadata":{"id":"vGZPBfEB0TyR"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1xqbwqIMwEUFiiH0KLsVhH41HPImc-IcH","timestamp":1671206110291},{"file_id":"1GN9iBkpCXnEkON6icDI8w8_Mz4EKKdZN","timestamp":1671065862036}],"authorship_tag":"ABX9TyN9Oahu3YQmWjXnMVriCYEw"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bbe61d231fe34f399b0cdfd1fd691e55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97301d20628b45c880fef6603a76f11e","IPY_MODEL_442146d539ef4c64b5491b965b120adf","IPY_MODEL_5b2602f1b2214b339c21b1f31cfe6c13"],"layout":"IPY_MODEL_a6bc7866312845f2afb4daea55738816"}},"97301d20628b45c880fef6603a76f11e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73934c7970c4a7699373713f3c4f90c","placeholder":"​","style":"IPY_MODEL_1ca4d501ef2347eaae4702ae407b037d","value":"100%"}},"442146d539ef4c64b5491b965b120adf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_993bfa8efd7a4d629ada360abd7e278b","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e00007bc358441e2a319c45d314c0bdc","value":553433881}},"5b2602f1b2214b339c21b1f31cfe6c13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_147bd8eaf26e4413aa4e4bf58072444b","placeholder":"​","style":"IPY_MODEL_dcbdb86a7b74462c9138c7b12bca41cc","value":" 528M/528M [00:06&lt;00:00, 80.2MB/s]"}},"a6bc7866312845f2afb4daea55738816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73934c7970c4a7699373713f3c4f90c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca4d501ef2347eaae4702ae407b037d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"993bfa8efd7a4d629ada360abd7e278b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e00007bc358441e2a319c45d314c0bdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"147bd8eaf26e4413aa4e4bf58072444b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcbdb86a7b74462c9138c7b12bca41cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}